{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e6f1fc-bff1-4983-975d-f6174fff5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "class Preprocessing:\n",
    "\n",
    "    @staticmethod\n",
    "    def read_dataset(file):\n",
    "\n",
    "        letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
    "                     'n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
    "\n",
    "        # Open raw file\n",
    "        with open(file, 'r') as f:\n",
    "            raw_text = f.readlines()\n",
    "\n",
    "        # Transform each line into lower\n",
    "        raw_text = [line.lower() for line in raw_text ]\n",
    "        \n",
    "        # Create a string which contains the entire text\n",
    "        text_string = ''\n",
    "        for line in raw_text:\n",
    "            text_string += line.strip()\n",
    "\n",
    "# Create an array by char\n",
    "        text = list()\n",
    "        for char in text_string:\n",
    "            text.append(char)\n",
    "\n",
    "# Remove all symbosl and just keep letters\n",
    "        text = [char for char in text  if char in letters]\n",
    "\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def create_dictionary(text):\n",
    "\n",
    "        char_to_idx = dict()\n",
    "        idx_to_char = dict()\n",
    "        \n",
    "        idx = 0\n",
    "        for char in text:\n",
    "            if char not in char_to_idx.keys():\n",
    "                char_to_idx[char] = idx\n",
    "                idx_to_char[idx] = char\n",
    "                idx += 1\n",
    "        \n",
    "        return char_to_idx, idx_to_char\n",
    "        \n",
    "    @staticmethod\n",
    "    def build_sequences_target(text, char_to_idx, window):\n",
    "        \n",
    "        x = list()\n",
    "        y = list()\n",
    "\n",
    "        for i in range(len(text)):\n",
    "            try:\n",
    "                # Get window of chars from text\n",
    "                # Then, transform it into its idx representation\n",
    "                sequence = text[i:i+window]\n",
    "                sequence = [char_to_idx[char] for char in sequence]\n",
    "                \n",
    "                # Get char target\n",
    "                # Then, transfrom it into its idx representation\n",
    "                target = text[i+window]\n",
    "                target = char_to_idx[target]\n",
    "                \n",
    "                # Save sequences and targets\n",
    "                x.append(sequence)\n",
    "                y.append(target)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d1c72e-70f1-4da3-98fe-da39507b209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parameter_parser():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description = \"Text Generation\")\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument(\"--epochs\", dest=\"num_epochs\", type=int, default=100)\n",
    "    parser.add_argument(\"--learning_rate\", dest=\"learning_rate\", type=float, default=0.005)\n",
    "    parser.add_argument(\"--hidden_dim\", dest=\"hidden_dim\", type=int, default=6)\n",
    "    parser.add_argument(\"--batch_size\", dest=\"batch_size\", type=int, default=2)\n",
    "    parser.add_argument(\"--window\", dest=\"window\", type=int, default=5)\n",
    "    parser.add_argument(\"--load_model\", dest=\"load_model\", type=bool, default=False)\n",
    "    parser.add_argument(\"--model\", dest=\"model\", type=str, default='weights/textGenerator.pt')\n",
    " \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95250c07-62d5-443a-a41d-f0fc252122a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML_cln\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextGenerator(nn.ModuleList):\n",
    "    def __init__(self, args, vocab_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "\n",
    "        self.batch_size = args.batch_size\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.input_size = vocab_size\n",
    "        self.num_classes = vocab_size\n",
    "        self.sequence_len = args.window\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_dim, padding_idx=0)\n",
    "\n",
    "        # Bi-LSTM\n",
    "        # Forward and backward\n",
    "        self.lstm_cell_forward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.lstm_cell_backward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm_cell = nn.LSTMCell(self.hidden_dim * 2, self.hidden_dim * 2)\n",
    "\n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Bi-LSTM\n",
    "        # hs = [batch_size x hidden_size]\n",
    "        # cs = [batch_size x hidden_size]\n",
    "        hs_forward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cs_forward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        hs_backward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cs_backward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        # hs = [batch_size x (hidden_size * 2)]\n",
    "        # cs = [batch_size x (hidden_size * 2)]\n",
    "        hs_lstm = torch.zeros(x.size(0), self.hidden_dim * 2)\n",
    "        cs_lstm = torch.zeros(x.size(0), self.hidden_dim * 2)\n",
    "\n",
    "        # Weights initialization\n",
    "        torch.nn.init.kaiming_normal_(hs_forward)\n",
    "        torch.nn.init.kaiming_normal_(cs_forward)\n",
    "        torch.nn.init.kaiming_normal_(hs_backward)\n",
    "        torch.nn.init.kaiming_normal_(cs_backward)\n",
    "        torch.nn.init.kaiming_normal_(hs_lstm)\n",
    "        torch.nn.init.kaiming_normal_(cs_lstm)\n",
    "\n",
    "\n",
    "        # From idx to embedding\n",
    "        out = self.embedding(x)\n",
    "\n",
    "        # Prepare the shape for LSTM Cells\n",
    "        out = out.view(self.sequence_len, x.size(0), -1)\n",
    "        \n",
    "        forward = []\n",
    "        backward = []\n",
    "        \n",
    "        # Unfolding Bi-LSTM\n",
    "        # Forward\n",
    "        for i in range(self.sequence_len):\n",
    "            hs_forward, cs_forward = self.lstm_cell_forward(out[i], (hs_forward, cs_forward))\n",
    "        forward.append(hs_forward)\n",
    "\n",
    "        # Backward\n",
    "        for i in reversed(range(self.sequence_len)):\n",
    "            hs_backward, cs_backward = self.lstm_cell_backward(out[i], (hs_backward, cs_backward))\n",
    "            backward.append(hs_backward)\n",
    "\n",
    "        # LSTM\n",
    "        for fwd, bwd in zip(forward, backward):\n",
    "            input_tensor = torch.cat((fwd, bwd), 1)\n",
    "            hs_lstm, cs_lstm = self.lstm_cell(input_tensor, (hs_lstm, cs_lstm))\n",
    "\n",
    "        # Last hidden state is passed through a linear layer\n",
    "        out = self.linear(hs_lstm)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b43b85-9298-49b4-b730-66bd8fef9a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  loss: 2.03803 \n",
      "Epoch: 1,  loss: 1.79939 \n",
      "Epoch: 2,  loss: 1.81270 \n",
      "Epoch: 3,  loss: 1.65167 \n",
      "Epoch: 4,  loss: 1.61717 \n",
      "Epoch: 5,  loss: 1.60446 \n",
      "Epoch: 6,  loss: 1.44311 \n",
      "Epoch: 7,  loss: 1.49331 \n",
      "Epoch: 8,  loss: 1.38388 \n",
      "Epoch: 9,  loss: 1.60384 \n",
      "Epoch: 10,  loss: 1.46723 \n",
      "Epoch: 11,  loss: 1.47592 \n",
      "Epoch: 12,  loss: 1.34274 \n",
      "Epoch: 13,  loss: 1.46378 \n",
      "Epoch: 14,  loss: 1.50576 \n",
      "Epoch: 15,  loss: 1.27657 \n",
      "Epoch: 16,  loss: 1.08034 \n",
      "Epoch: 17,  loss: 1.01937 \n",
      "Epoch: 18,  loss: 1.12431 \n",
      "Epoch: 19,  loss: 1.18418 \n",
      "Epoch: 20,  loss: 1.16331 \n",
      "Epoch: 21,  loss: 0.99330 \n",
      "Epoch: 22,  loss: 0.96192 \n",
      "Epoch: 23,  loss: 1.00864 \n",
      "Epoch: 24,  loss: 0.95013 \n",
      "Epoch: 25,  loss: 1.11932 \n",
      "Epoch: 26,  loss: 1.12787 \n",
      "Epoch: 27,  loss: 0.99113 \n",
      "Epoch: 28,  loss: 1.14227 \n",
      "Epoch: 29,  loss: 1.19187 \n",
      "Epoch: 30,  loss: 1.19786 \n",
      "Epoch: 31,  loss: 1.05300 \n",
      "Epoch: 32,  loss: 1.47006 \n",
      "Epoch: 33,  loss: 1.12750 \n",
      "Epoch: 34,  loss: 0.87186 \n",
      "Epoch: 35,  loss: 0.99905 \n",
      "Epoch: 36,  loss: 1.10778 \n",
      "Epoch: 37,  loss: 1.09816 \n",
      "Epoch: 38,  loss: 1.28518 \n",
      "Epoch: 39,  loss: 1.04398 \n",
      "Epoch: 40,  loss: 1.34681 \n",
      "Epoch: 41,  loss: 1.15748 \n",
      "Epoch: 42,  loss: 1.30809 \n",
      "Epoch: 43,  loss: 1.19411 \n",
      "Epoch: 44,  loss: 0.95097 \n",
      "Epoch: 45,  loss: 0.85674 \n",
      "Epoch: 46,  loss: 1.01719 \n",
      "Epoch: 47,  loss: 1.15339 \n",
      "Epoch: 48,  loss: 1.18602 \n",
      "Epoch: 49,  loss: 1.08060 \n",
      "Epoch: 50,  loss: 1.57495 \n",
      "Epoch: 51,  loss: 1.16763 \n",
      "Epoch: 52,  loss: 1.33124 \n",
      "Epoch: 53,  loss: 1.21660 \n",
      "Epoch: 54,  loss: 1.01956 \n",
      "Epoch: 55,  loss: 1.15916 \n",
      "Epoch: 56,  loss: 1.14915 \n",
      "Epoch: 57,  loss: 1.08776 \n",
      "Epoch: 58,  loss: 0.89299 \n",
      "Epoch: 59,  loss: 1.01415 \n",
      "Epoch: 60,  loss: 1.08960 \n",
      "Epoch: 61,  loss: 1.15680 \n",
      "Epoch: 62,  loss: 0.92476 \n",
      "Epoch: 63,  loss: 1.07967 \n",
      "Epoch: 64,  loss: 1.09326 \n",
      "Epoch: 65,  loss: 1.12920 \n",
      "Epoch: 66,  loss: 1.06781 \n",
      "Epoch: 67,  loss: 1.17619 \n",
      "Epoch: 68,  loss: 1.13008 \n",
      "Epoch: 69,  loss: 1.00554 \n",
      "Epoch: 70,  loss: 0.99865 \n",
      "Epoch: 71,  loss: 0.94109 \n",
      "Epoch: 72,  loss: 0.93433 \n",
      "Epoch: 73,  loss: 0.92326 \n",
      "Epoch: 74,  loss: 0.84172 \n",
      "Epoch: 75,  loss: 0.90753 \n",
      "Epoch: 76,  loss: 0.97243 \n",
      "Epoch: 77,  loss: 0.79253 \n",
      "Epoch: 78,  loss: 0.95563 \n",
      "Epoch: 79,  loss: 0.85034 \n",
      "Epoch: 80,  loss: 0.97241 \n",
      "Epoch: 81,  loss: 0.97730 \n",
      "Epoch: 82,  loss: 0.90492 \n",
      "Epoch: 83,  loss: 0.99642 \n",
      "Epoch: 84,  loss: 0.91423 \n",
      "Epoch: 85,  loss: 0.98130 \n",
      "Epoch: 86,  loss: 0.96915 \n",
      "Epoch: 87,  loss: 0.88965 \n",
      "Epoch: 88,  loss: 1.14466 \n",
      "Epoch: 89,  loss: 0.91518 \n",
      "Epoch: 90,  loss: 0.93640 \n",
      "Epoch: 91,  loss: 0.95872 \n",
      "Epoch: 92,  loss: 0.82834 \n",
      "Epoch: 93,  loss: 0.94448 \n",
      "Epoch: 94,  loss: 0.85498 \n",
      "Epoch: 95,  loss: 1.01007 \n",
      "Epoch: 96,  loss: 1.36811 \n",
      "Epoch: 97,  loss: 0.99151 \n",
      "Epoch: 98,  loss: 0.84705 \n",
      "Epoch: 99,  loss: 0.81222 \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first 5 letters of the song:  onamp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text entered:\n",
      "onamp\n",
      "\n",
      "Song prediction: \n",
      "onamponnamarana pova\n",
      "Actual Song: Onam ponnonam poomala pongum...\n",
      "Youtube link: https://youtu.be/kxw-EO-6Z8I\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from txtge import TextGenerator\n",
    "# from mod import Preprocessing\n",
    "# from mod import parameter_parser\n",
    "\n",
    "class Execution:\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.file = 'data/dataset.txt'\n",
    "        self.window = args.window\n",
    "        self.batch_size = args.batch_size\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.num_epochs = args.num_epochs\n",
    "        \n",
    "        self.targets = None\n",
    "        self.sequences = None\n",
    "        self.vocab_size = None\n",
    "        self.char_to_idx = None\n",
    "        self.idx_to_char = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        # Initialize preprocessor object\n",
    "        preprocessing = Preprocessing()\n",
    "\n",
    "        # The 'file' is loaded and split by char\n",
    "        text = preprocessing.read_dataset(self.file)\n",
    "\n",
    "        # Given 'text', it is created two dictionaries\n",
    "        # a dictiornary about: from char to index\n",
    "        # a dictorionary about: from index to char\n",
    "        self.char_to_idx, self.idx_to_char = preprocessing.create_dictionary(text)\n",
    "        \n",
    "        # Given the 'window', it is created the set of training sentences as well as\n",
    "        # the set of target chars\n",
    "        self.sequences, self.targets = preprocessing.build_sequences_target(text, self.char_to_idx, window=self.window)\n",
    "        \n",
    "        # Gets the vocabuly size\n",
    "        self.vocab_size = len(self.char_to_idx)\n",
    "\n",
    "\n",
    "    def train(self, args):\n",
    "\n",
    "        # Model initialization\n",
    "        model = TextGenerator(args, self.vocab_size)\n",
    "        # Optimizer initialization\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=self.learning_rate)\n",
    "        # Defining number of batches\n",
    "        num_batches = int(len(self.sequences) / self.batch_size)\n",
    "        # Set model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Training pahse\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Mini batches\n",
    "            for i in range(num_batches):\n",
    "\n",
    "                # Batch definition\n",
    "                try:\n",
    "                    x_batch = self.sequences[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                    y_batch = self.targets[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                except:\n",
    "                    x_batch = self.sequences[i * self.batch_size :]\n",
    "                    y_batch = self.targets[i * self.batch_size :]\n",
    "\n",
    "                # Convert numpy array into torch tensors\n",
    "                x = torch.from_numpy(x_batch).type(torch.LongTensor)\n",
    "                y = torch.from_numpy(y_batch).type(torch.LongTensor)\n",
    "                \n",
    "                # Feed the model\n",
    "                y_pred = model(x)\n",
    "                # Loss calculation\n",
    "                loss = F.cross_entropy(y_pred, y.squeeze())\n",
    "                # Clean gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Calculate gradientes\n",
    "                loss.backward()\n",
    "                # Updated parameters\n",
    "\n",
    "                optimizer.step()\n",
    "        \n",
    "            print(\"Epoch: %d,  loss: %.5f \" % (epoch, loss.item()))\n",
    "\n",
    "\n",
    "        torch.save(model.state_dict(), 'weights/textGenerator_model.pt')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generator(model, seq, idx_to_char, char_to_idx, n_chars):\n",
    "        \n",
    "        # Set the model in evalulation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Define the softmax function\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        a = (char_to_idx[value] for value in seq)\n",
    "        x = (tuple(a))\n",
    "        #print(x)\n",
    "\n",
    "        # The inputted text is converted to a tuple and is given to pattern\n",
    "        pattern = x\n",
    "        \n",
    "        # By making use of the dictionaries, it is printed the pattern\n",
    "        print(\"\\nText entered:\")\n",
    "        print(''.join([idx_to_char[value] for value in pattern]))\n",
    "        \n",
    "        # In full_prediction we will save the complete prediction\n",
    "        # tuple is converted to numpy array\n",
    "        pattern = np.asarray(pattern)\n",
    "        full_prediction = pattern\n",
    "        # The prediction starts, it is going to be predicted a given\n",
    "      # number of characters\n",
    "        for i in range(n_chars):\n",
    "        \n",
    "            # The numpy patterns is transformed into a tesor-type and reshaped\n",
    "            pattern = torch.from_numpy(pattern).type(torch.LongTensor)\n",
    "            pattern = pattern.view(1,-1)\n",
    "            \n",
    "            # Make a prediction given the pattern\n",
    "            prediction = model(pattern)\n",
    "            # It is applied the softmax function to the predicted tensor\n",
    "            prediction = softmax(prediction)\n",
    "            \n",
    "            # The prediction tensor is transformed into a numpy array\n",
    "            prediction = prediction.squeeze().detach().numpy()\n",
    "            # It is taken the idx with the highest probability\n",
    "            arg_max = np.argmax(prediction)\n",
    "            \n",
    "            # The current pattern tensor is transformed into numpy array\n",
    "            pattern = pattern.squeeze().detach().numpy()\n",
    "            # The window is sliced 1 character to the right\n",
    "            pattern = pattern[1:]\n",
    "            # The new pattern is composed by the \"old\" pattern + the predicted character\n",
    "            pattern = np.append(pattern, arg_max)\n",
    "            \n",
    "            # The full prediction is saved\n",
    "            full_prediction = np.append(full_prediction, arg_max)\n",
    "            \n",
    "        print(\"\\nSong prediction: \")\n",
    "        print(''.join([idx_to_char[value] for value in full_prediction]) )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    args = parameter_parser()\n",
    "\n",
    "    # If you already have the trained weights\n",
    "    if args.load_model == True:\n",
    "        if os.path.exists(args.model):\n",
    "            \n",
    "            # Load and prepare sequences\n",
    "            execution = Execution(args)\n",
    "            execution.prepare_data()\n",
    "            \n",
    "            seq = execution.seq\n",
    "            idx_to_char = execution.idx_to_char\n",
    "            vocab_size = execution.vocab_size\n",
    "            char_to_idx = execution.char_to_idx\n",
    "\n",
    "            # Initialize the model\n",
    "            model = TextGenerator(args, vocab_size)\n",
    "            \n",
    "            # Load weights\n",
    "            model.load_state_dict(torch.load('weights/textGenerator_model.pt'))\n",
    "            seq = input(\"Enter the first 5 letters of the song: \")\n",
    "            # Text generator\n",
    "            \n",
    "            execution.generator(model,seq , idx_to_char, char_to_idx,15)\n",
    "\n",
    "            \n",
    "\n",
    "    # If you will train the model \t\t\n",
    "    else:\n",
    "        # Load and preprare the sequences\n",
    "        execution = Execution(args)\n",
    "        execution.prepare_data()\n",
    "        \n",
    "        # Training the model\n",
    "        execution.train(args)\n",
    "        sequences = execution.sequences\n",
    "        idx_to_char = execution.idx_to_char\n",
    "        vocab_size = execution.vocab_size\n",
    "        char_to_idx = execution.char_to_idx\n",
    "        # Initialize the model\n",
    "        model = TextGenerator(args, vocab_size)\n",
    "        # Load weights\n",
    "        model.load_state_dict(torch.load('weights/textGenerator_model.pt'))\n",
    "        seq = input(\"Enter the first 5 letters of the song: \")\n",
    "        # Text generator\n",
    "        execution.generator(model, seq, idx_to_char, char_to_idx,15)\n",
    "        \n",
    "pickle.dump(model, open('model.pkl', 'wb'))\n",
    "                        \n",
    "if seq.lower() == 'uthra':\n",
    "    print('Actual Song: Uthrada poonilaave vaa....')\n",
    "    print('Youtube link: https://youtu.be/0QtNxqAZlXQ')\n",
    "elif seq.lower() == 'onamn':\n",
    "    print('Actual Song: Onam nilavile pole onam kinavithal pole...')\n",
    "    print('Youtube link: https://youtu.be/W_lWEvwhlbU')\n",
    "elif seq.lower()  == 'onamp':\n",
    "    print('Actual Song: Onam ponnonam poomala pongum...')\n",
    "    print('Youtube link: https://youtu.be/kxw-EO-6Z8I')\n",
    "elif seq.lower() == 'onamv':\n",
    "    print('Actual Song: Onam vannallo oonjaalittallo...')\n",
    "    print('Youtube link: https://youtu.be/oaSMBo7FYkM')\n",
    "elif seq.lower() == 'mavel':\n",
    "    print('Actual Song: Maveli nadu vaneedum kalam...')\n",
    "    print('Youtube link: https://youtu.be/4XsmZvalkUY')\n",
    "elif seq.lower() == 'kutta':\n",
    "    print('Actual Song: Kuttanadan Punjayile...')\n",
    "    print('Youtube link: https://youtu.be/s2R_geXB174')\n",
    "elif seq.lower() == 'Onapo':\n",
    "    print('Actual Song: Onapove omal pove Ppookudiyan...')\n",
    "    print('Youtube link: https://youtu.be/c0FHgOkqe1U')\n",
    "else:\n",
    "    print('Unable to find the song!! Please try some other song.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2406a980-8e30-4ed6-a31e-3c43bd9755ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "while 1:\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r.listen(source)\n",
    "        \n",
    "        try:\n",
    "            filename =  \"draft.txt\"\n",
    "            f = open(filename, \"a+\")\n",
    "            \n",
    "            recognized_text = r.recognize_google(audio)\n",
    "            print(recognized_text)\n",
    "            remainder = recognized_text.split()\n",
    "            while remainder:\n",
    "                line, remainder = remainder[:12], remainder[12:]\n",
    "                f.write(' '.join(line))\n",
    "            if recognized_text == 'stop':\n",
    "                break\n",
    "                \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Unable to Understand the audio\")\n",
    "        except sr.RequestErrror as o:\n",
    "            print(\"Error: (o)\".format(o))\n",
    "            \n",
    "        break      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f409d51d-9243-4d4a-87e6-a6dc6742038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Please try ones again\n",
      "Unable to find the actual song!! Please try some other song.\n"
     ]
    }
   ],
   "source": [
    "from mains import Execution\n",
    "\n",
    "\n",
    "with open('draft.txt', 'r') as f:\n",
    "    fil = f.read()\n",
    "    print(fil)\n",
    "fil = fil.lower()\n",
    "if len(fil) == 5 and(fil=='uthra'or fil=='onamn'or fil =='onamp'or fil =='onamv'or fil =='mavel'or fil =='kutta'or fil =='Onapo'):\n",
    "    \n",
    "    h = Execution(args)\n",
    "    h.prepare_data()\n",
    "        \n",
    "    # Training the model\n",
    "    h.train(args)\n",
    "    sequences = h.sequences\n",
    "    idx_to_char = h.idx_to_char\n",
    "    vocab_size = h.vocab_size\n",
    "    char_to_idx = h.char_to_idx\n",
    "    # Initialize the model\n",
    "    model = TextGenerator(args, vocab_size)\n",
    "    h.generator(model, fil, idx_to_char, char_to_idx,15)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"Please try ones again\")\n",
    "\n",
    "if fil.lower() == 'uthra':\n",
    "    print('Actual Song: Uthrada poonilaave vaa....')\n",
    "    print('Youtube link: https://youtu.be/0QtNxqAZlXQ')\n",
    "elif fil.lower() == 'onamn':\n",
    "    print('Actual Song: Onam nilavile pole onam kinavithal pole...')\n",
    "    print('Youtube link: https://youtu.be/W_lWEvwhlbU')\n",
    "elif fil.lower()  == 'onamp':\n",
    "    print('Actual Song: Onam ponnonam poomala pongum...')\n",
    "    print('Youtube link: https://youtu.be/kxw-EO-6Z8I')\n",
    "elif fil.lower() == 'onamv':\n",
    "    print('Actual Song: Onam vannallo oonjaalittallo...')\n",
    "    print('Youtube link: https://youtu.be/oaSMBo7FYkM')\n",
    "elif fil.lower() == 'mavel':\n",
    "    print('Actual Song: Maveli nadu vaneedum kalam...')\n",
    "    print('Youtube link: https://youtu.be/4XsmZvalkUY')\n",
    "elif fil.lower() == 'kutta':\n",
    "    print('Actual Song: Kuttanadan Punjayile...')\n",
    "    print('Youtube link: https://youtu.be/s2R_geXB174')\n",
    "elif fil.lower() == 'Onapo':\n",
    "    print('Actual Song: Onapove omal pove Ppookudiyan...')\n",
    "    print('Youtube link: https://youtu.be/c0FHgOkqe1U')\n",
    "else:\n",
    "    print('Unable to find the actual song!! Please try some other song.')\n",
    "    \n",
    "file = open('draft.txt', 'w')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49954e-cba2-4a51-a26a-bd63d7760752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
